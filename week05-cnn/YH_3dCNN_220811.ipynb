{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9ac389",
   "metadata": {},
   "source": [
    "#Lab 11 MNIST and Deep Learning CNN\n",
    "#(https://wikidocs.net/60324 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac9cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import torch.nn.init\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa4011d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reproducible한 실험을 하기 위해 시드를 고정해둘 필요가 있다. \n",
    "#Pytorch에서 무작위성을 배제하고 일관된 학습 결과를 얻으려면 다음과 같은 코드를 사용하면 된다. \n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855c3d2",
   "metadata": {},
   "source": [
    "(https://moding.tistory.com/entry/Learning-Rate-Training-Epoch-Batch-Size%EC%9D%98-%EC%9D%98%EB%AF%B8)\n",
    "learning_rate training epochs, batch_size 개념\n",
    "1) learning_rate : alpha값, 기울기의 변화폭을 정해주는데 너무 커도, 너무작아도 안되므로 보통 lr=0.01로 시작한다.\n",
    "2) 1 epoch : 전체 데이터셋에 대해 한 번 학습을 완료한 상태\n",
    "3) batch_size : 한번 학습을 할때 데이터를 쪼갠 크기, 메모리의 한계와 속도 저하를 막기 위해\n",
    "4) iteration : 1000개의 데이터셋, batch_size = 100이면 1epoch = 1000/batch_size = 10 iteration\n",
    "\n",
    "### 뿐만아니라, transforms를 정의할 수 있고, shuffle, num_workers를 정의하는 등 다양한 option 값으로 매우 손 쉽게 datasets를 컨트롤 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f256248",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':15,\n",
    "    'LEARNING_RATE':1e-3,\n",
    "    'BATCH_SIZE':16,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e0586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c82fb4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"train.h5\" (mode r)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_csv('C:/Users/sarah/data/open/train.csv')\n",
    "all_points = h5py.File('C:/Users/sarah/data/open/train.h5', 'r')\n",
    "\n",
    "all_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2397437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  label\n",
       "0   0      5\n",
       "1   1      0\n",
       "2   2      4\n",
       "3   3      1\n",
       "4   4      9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = all_df.iloc[:int(len(all_df)*0.8)]\n",
    "val_df = all_df.iloc[int(len(all_df)*0.8):]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3bce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "img_name = ('train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47782f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, id_list, label_list, point_list):\n",
    "        self.id_list = id_list\n",
    "        self.label_list = label_list\n",
    "        self.point_list = point_list\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.id_list[index]\n",
    "        \n",
    "        # h5파일을 바로 접근하여 사용하면 학습 속도가 병목 현상으로 많이 느릴 수 있습니다.\n",
    "        points = self.point_list[str(image_id)][:]\n",
    "        image = self.get_vector(points)\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return torch.Tensor(image).unsqueeze(0), label\n",
    "        else:\n",
    "            return torch.Tensor(image).unsqueeze(0)\n",
    "    \n",
    "    def get_vector(self, points, x_y_z=[16, 16, 16]):\n",
    "        # 3D Points -> [16,16,16]\n",
    "        xyzmin = np.min(points, axis=0) - 0.001\n",
    "        xyzmax = np.max(points, axis=0) + 0.001\n",
    "\n",
    "        diff = max(xyzmax-xyzmin) - (xyzmax-xyzmin)\n",
    "        xyzmin = xyzmin - diff / 2\n",
    "        xyzmax = xyzmax + diff / 2\n",
    "\n",
    "        segments = []\n",
    "        shape = []\n",
    "\n",
    "        for i in range(3):\n",
    "            # note the +1 in num \n",
    "            if type(x_y_z[i]) is not int:\n",
    "                raise TypeError(\"x_y_z[{}] must be int\".format(i))\n",
    "            s, step = np.linspace(xyzmin[i], xyzmax[i], num=(x_y_z[i] + 1), retstep=True)\n",
    "            segments.append(s)\n",
    "            shape.append(step)\n",
    "\n",
    "        n_voxels = x_y_z[0] * x_y_z[1] * x_y_z[2]\n",
    "        n_x = x_y_z[0]\n",
    "        n_y = x_y_z[1]\n",
    "        n_z = x_y_z[2]\n",
    "\n",
    "        structure = np.zeros((len(points), 4), dtype=int)\n",
    "        structure[:,0] = np.searchsorted(segments[0], points[:,0]) - 1\n",
    "        structure[:,1] = np.searchsorted(segments[1], points[:,1]) - 1\n",
    "        structure[:,2] = np.searchsorted(segments[2], points[:,2]) - 1\n",
    "\n",
    "        # i = ((y * n_x) + x) + (z * (n_x * n_y))\n",
    "        structure[:,3] = ((structure[:,1] * n_x) + structure[:,0]) + (structure[:,2] * (n_x * n_y)) \n",
    "\n",
    "        vector = np.zeros(n_voxels)\n",
    "        count = np.bincount(structure[:,3])\n",
    "        vector[:len(count)] = count\n",
    "\n",
    "        vector = vector.reshape(n_z, n_y, n_x)\n",
    "        return vector\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9de5eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "train_dataset = CustomDataset(train_df['ID'].values, train_df['label'].values, all_points)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_df['ID'].values, val_df['label'].values, all_points)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f30bc",
   "metadata": {},
   "source": [
    "### drop_last = True\n",
    "drop_last를 하는 이유를 이해하기 위해서 1,000개의 데이터가 있다고 했을 때, 배치 크기가 128이라고 해봅시다. 1,000을 128로 나누면 총 7개가 나오고 나머지로 104개가 남습니다. 이때 104개를 마지막 배치로 한다고 하였을 때 128개를 충족하지 못하였으므로 104개를 그냥 버릴 수도 있습니다. 이때 마지막 배치를 버리려면 drop_last=True를 해주면 됩니다. 이는 다른 미니 배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여 마지막 배치가 상대적으로 과대 평가되는 현상을 막아줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6133c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN MODEL\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2))\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2))\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2, padding=1))\n",
    "        #-------------------------------------------------------------#\n",
    "        self.fc1 = nn.Linear(3*3*3 * 128, 625, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight) #가중치 초기화 : xavier_uniform or HE_uniform 방법이 주로 쓰이는데 he_uniform이 최근 자주쓰임\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(p=1 - self.keep_prob))\n",
    "        \n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = nn.Linear(625, 10, bias=True)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.layer4(out)\n",
    "        out = self.fc2(out)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13d6d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate CNN model\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeaf0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "#cross entrophy : info가 틀릴수 있는 정도(확률), softmax(Q라고 쓰임) : Estimated Probability, P는 True Probability이다.\n",
    "\n",
    "# torch.nn.CrossEntropyLoss는 nn.LogSoftmax와 nn.NLLLoss의 연산의 조합이다.\n",
    "#nn.LogSoftmax는 신경망 말단의 결과 값들을 확률개념으로 해석하기 위한 Softmax 함수의 결과에 log 값을 취한 연산이고,\n",
    "#nn.NLLLoss는 nn.LogSoftmax의 log 결과값에 대한 교차 엔트로피 손실 연산(Cross Entropy Loss|Error)\n",
    "criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed. \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "#머신러닝 알고리즘에서 최적화는 비용함수의 값이 가장 작아지는 최적의 파라미터를 찾는 과정을 말하며, 비용함수는 손실함수를 사용하여 정의될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "485a2c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. Waiting for training\n",
      "[Epoch:    1] cost = 0.382512152\n",
      "[Epoch:    2] cost = 0.152759239\n",
      "[Epoch:    3] cost = 0.120004125\n",
      "[Epoch:    4] cost = 0.0873160064\n",
      "[Epoch:    5] cost = 0.0743927658\n",
      "[Epoch:    6] cost = 0.0630536675\n",
      "[Epoch:    7] cost = 0.0509901792\n",
      "[Epoch:    8] cost = 0.0424067266\n",
      "[Epoch:    9] cost = 0.0366119742\n",
      "[Epoch:   10] cost = 0.0303025246\n",
      "[Epoch:   11] cost = 0.0296249781\n",
      "[Epoch:   12] cost = 0.0262725595\n",
      "[Epoch:   13] cost = 0.0228511039\n",
      "[Epoch:   14] cost = 0.0186515767\n",
      "[Epoch:   15] cost = 0.0200849827\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# # train my model\n",
    "# total_batch = len(train_loader)\n",
    "# model.train()    # set the model to train mode (dropout=True)\n",
    "# print('Learning started. Waiting for training')\n",
    "# for epoch in range(CFG['EPOCHS']):\n",
    "#     avg_cost = 0\n",
    "\n",
    "#     for X, Y in train_loader:\n",
    "#         X = X.to(device)\n",
    "#         Y = Y.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         hypothesis = model(X)\n",
    "#         cost = criterion(hypothesis, Y)\n",
    "#         cost.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         avg_cost += cost / total_batch\n",
    "\n",
    "#     print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
    "\n",
    "# print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64e2eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    best_score = 0\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for data, label in tqdm(iter(train_loader)):\n",
    "            data, label = data.float().to(device), label.long().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        val_loss, val_acc = validation(model, criterion, val_loader, device)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss)}] Val Loss : [{val_loss}] Val ACC : [{val_acc}]')\n",
    "        \n",
    "        if best_score < val_acc:\n",
    "            best_score = val_acc\n",
    "            torch.save(model.state_dict(), './best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2834aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    model_preds = []\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in tqdm(iter(val_loader)):\n",
    "            data, label = data.float().to(device), label.long().to(device)\n",
    "            \n",
    "            model_pred = model(data)\n",
    "            loss = criterion(model_pred, label)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            model_preds += model_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += label.detach().cpu().numpy().tolist()\n",
    "    \n",
    "    return np.mean(val_loss), accuracy_score(true_labels, model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7beb7f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c4b2561d914f188327682908eb8462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef56790346454a28b5facf80109b4b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.38435008316840974] Val Loss : [0.097418234183616] Val ACC : [0.9707]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39539010ec546fca1fc841cac816b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67137c6042cb4e9aa6a64a2e67df8631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.14472704893104382] Val Loss : [0.09865006480483281] Val ACC : [0.9718]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e108a99eac414dc0aa10d94a280aa18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e069b8cb31642738ddf92835fcee2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.10960012826781021] Val Loss : [0.0832768002491066] Val ACC : [0.9771]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18ec50e153e42e4a674b9bd49839a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987ed2ee93f24afbb1bbcca5701cbcf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.08674982716359264] Val Loss : [0.06685446433901461] Val ACC : [0.9808]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0aabd58bc1400c98580c71684f744c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab34277fa7c4489ab70829ff61232330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.06939612549450849] Val Loss : [0.07443402448451616] Val ACC : [0.9792]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad1451ab7894caeb42c6d0f2e422254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1dd575dca6e4d39875f7faee2860684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6] Train Loss : [0.05722450754153233] Val Loss : [0.0717786738259435] Val ACC : [0.9798]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae66b57f71044d0a5951a9b929ad053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34549bc792b841b791703b1b2ee4ba89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7] Train Loss : [0.04579911838452133] Val Loss : [0.0598914767855696] Val ACC : [0.9852]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5a9ea60590417190cdc298790520f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dddee7058174ceaa99c647eda73d0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8] Train Loss : [0.039477783858499836] Val Loss : [0.07272385757855122] Val ACC : [0.9831]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e946f3f60b024c83ae93390481b44f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7b0135a2c4403282cf5bc8a7d2d0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9] Train Loss : [0.03500213744475137] Val Loss : [0.06055688240901911] Val ACC : [0.9867]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1212943ff6a842ab9d3cef5e1a413204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a63167038554682b957501639fdb69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10] Train Loss : [0.031162121261334438] Val Loss : [0.0651469782557637] Val ACC : [0.9866]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e16532b80334859b74f28dff6c9428b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af794c5f187450581074265b6deef43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [11] Train Loss : [0.02535970654199184] Val Loss : [0.09418634606537185] Val ACC : [0.9819]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fbf58d8e4245aa988e0a12d77f52a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc01f2af8a2d4d1a8aefac5f3d7fd068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [12] Train Loss : [0.02485044515351085] Val Loss : [0.09033163655648632] Val ACC : [0.9847]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afe8e401d664152bb83851e92c531f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a23cb3e8514619b1b01d130d447234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [13] Train Loss : [0.02395698805882818] Val Loss : [0.0768574696806924] Val ACC : [0.9853]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200a2cd739394fc0af33701cdad860b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486748d646e0435f855e2d8bbda44be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [14] Train Loss : [0.020003415417765406] Val Loss : [0.09595837879376817] Val ACC : [0.9842]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f0907f03a541aebbf2cf77ec4cebb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc83995c6d054bdcab60361678102194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [15] Train Loss : [0.021011208806646038] Val Loss : [0.10773235138708169] Val ACC : [0.984]\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = None\n",
    "\n",
    "train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2192542d",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "862d0f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('C:/Users/sarah/data/open/sample_submission.csv')\n",
    "test_points = h5py.File('C:/Users/sarah/data/open/test.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d1d7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_df['ID'].values, None, test_points)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b49cbdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool3d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=3456, out_features=625, bias=True)\n",
       "  (layer4): Sequential(\n",
       "    (0): Linear(in_features=3456, out_features=625, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc2): Linear(in_features=625, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('./best_model.pth')\n",
    "model = CNN()\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1850382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    model_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(iter(test_loader)):\n",
    "            data = data.float().to(device)\n",
    "            \n",
    "            batch_pred = model(data)\n",
    "            \n",
    "            model_preds += batch_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    return model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de0d8059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf750c2b3544dd5bd29991f8a4889ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = predict(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecbd60",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61ee53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'] = preds\n",
    "test_df.to_csv('C:/Users/sarah/data/open/submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
