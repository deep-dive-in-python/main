{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=400\n",
    "LR=1e-2\n",
    "BS=16384\n",
    "SEED=41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 시드 고정 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    ## 위에서 random.seed 지정해줬는데 왜 np.random 지정해야하는지 모르겠음!!\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "2 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
      "3 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
      "4 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
      "\n",
      "         V8        V9       V10    ...          V21       V22       V23  \\\n",
      "0  0.247676 -1.514654  0.207643    ...     0.247998  0.771679  0.909412   \n",
      "1  0.377436 -1.387024 -0.054952    ...    -0.108300  0.005274 -0.190321   \n",
      "2  0.260314 -0.568671 -0.371407    ...    -0.208254 -0.559825 -0.026398   \n",
      "3 -3.807864  0.615375  1.249376    ...     1.943465 -1.015455  0.057504   \n",
      "4  0.851084 -0.392048 -0.410430    ...    -0.073425 -0.268092 -0.204233   \n",
      "\n",
      "        V24       V25       V26       V27       V28       V29       V30  \n",
      "0 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  4.983721 -0.994972  \n",
      "1 -1.175575  0.647376 -0.221929  0.062723  0.061458  1.418291 -0.994972  \n",
      "2 -0.371427 -0.232794  0.105915  0.253844  0.081080 -0.256131 -0.994960  \n",
      "3 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339  0.262698 -0.994901  \n",
      "4  1.011592  0.373205 -0.384157  0.011747  0.142404  0.994900 -0.994901  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "         V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
      "1  0.962496  0.328461 -0.171479  2.109204  1.129566  1.696038  0.107712   \n",
      "2  1.145524  0.575068  0.194008  2.598192 -0.092210 -1.044430  0.531588   \n",
      "3  0.927060 -0.323684  0.387585  0.544474  0.246787  1.650358 -0.427576   \n",
      "4 -3.005237  2.600138  1.483691 -2.418473  0.306326 -0.824575  2.065426   \n",
      "\n",
      "         V8        V9       V10  ...         V22       V23       V24  \\\n",
      "0  0.069539 -0.736727 -0.366846  ...   -0.633753 -0.120794 -0.385050   \n",
      "1  0.521502 -1.191311  0.724396  ...    0.402492 -0.048508 -1.371866   \n",
      "2 -0.241888 -0.896287  0.757952  ...   -0.119703 -0.076510  0.691320   \n",
      "3  0.615371  0.226278 -0.225495  ...    0.079359  0.096632 -0.992569   \n",
      "4 -1.829347  4.009259  6.051521  ...   -0.181268 -0.163747  0.515821   \n",
      "\n",
      "        V25       V26       V27       V28       V29       V30  Class  \n",
      "0 -0.069733  0.094199  0.246219  0.083076 -0.255991 -0.994878      0  \n",
      "1  0.390814  0.199964  0.016371 -0.014605  0.168937 -0.994784      0  \n",
      "2  0.633984  0.048741 -0.053192  0.016251  0.169496 -0.994502      0  \n",
      "3  0.085096  0.377447  0.036096 -0.005960  0.331307 -0.994467      0  \n",
      "4  0.136318  0.460054 -0.251259 -1.105751 -0.287012 -0.994373      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./input/train.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "print(train_df.head())\n",
    "\n",
    "val_df = pd.read_csv('./input/val.csv')\n",
    "val_df = val_df.drop(columns=['ID'])\n",
    "print(val_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113842, 30)\n",
      "(28462, 31)\n"
     ]
    }
   ],
   "source": [
    "#데이터 차원 확인\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, validation):\n",
    "        self.df = df\n",
    "        self.validation = validation\n",
    "        if self.validation:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.validation:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    #eval_mode -> validation 변경\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(df=train_df, validation=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=6)\n",
    "\n",
    "val_dataset = MyDataset(df = val_df, validation=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 1D AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(30,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64,30),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        return x\n",
    "    \n",
    "    #leakyrelu -> relu or tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        \n",
    "    def fit(self, ):\n",
    "        self.model.to(self.device)\n",
    "        best_score = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            for x in iter(self.train_loader):\n",
    "                x = x.float().to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                _x = self.model(x)\n",
    "                loss = mean_squared_error(x, _x)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            score = self.validation(self.model, 0.95)\n",
    "            print('Epoch : [{}] Train loss : [{}] Val Score : [{}])'.format(epoch, np.mean(train_loss), score))\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(score)\n",
    "\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n",
    "    \n",
    "    def validation(self, eval_model, thr):\n",
    "        eval_model.eval()\n",
    "        pred = []\n",
    "        true = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.val_loader):\n",
    "                x = x.float().to(self.device)\n",
    "\n",
    "                _x = self.model(x)\n",
    "                diff = mean_squared_error(x, _x).cpu().tolist()\n",
    "                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
    "                # 여기서 thr을 조정해주고 싶은데 뭘 바꿔야할지 모르겠음!!!\n",
    "                pred += batch_pred\n",
    "                true += y.tolist()\n",
    "\n",
    "        return f1_score(true, pred, average='macro')\n",
    "    \n",
    "    # loss function, cos -> MAE, MSE, ,RMSE, MAPE, MPE\n",
    "    # loss backward -> loss forward\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-82571484d2ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-4f978d4d5ee1>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \"\"\"\n\u001b[1;32m    237\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 238\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    239\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[1;32m    240\u001b[0m                                weights=sample_weight)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "model = nn.DataParallel(AutoEncoder())\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-2, verbose=True)\n",
    "\n",
    "trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()\n",
    "model.load_state_dict(torch.load('./best_model.pth'))\n",
    "model = nn.DataParallel(model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./input/test.csv')\n",
    "test_df = test_df.drop(columns=['ID'])\n",
    "\n",
    "test_dataset = MyDataset(test_df, False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=6)\n",
    "\n",
    "def prediction(model, thr, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for x in iter(test_loader):\n",
    "            x = x.float().to(device)\n",
    "            \n",
    "            _x = model(x)\n",
    "            \n",
    "            diff = cos(x, _x).cpu().tolist()\n",
    "            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
    "            pred += batch_pred\n",
    "    return pred\n",
    "\n",
    "preds = prediction(model, 0.95, test_loader, device)\n",
    "\n",
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['Class'] = preds\n",
    "submit.to_csv('./submit_autoencoder.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
